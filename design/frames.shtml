#define S_DOCUMENTATION
#define S_DOCUMENTATION_DEVELOPER
#define PAGE Documentation
#define SUBPAGE Developers: Frames

#include "header.shtml"

<h2>Compound Frame Handling</h2>
<p>
Author: <a href="mailto:eilemann@gmail.com">eilemann@gmail.com</a><br/>
</p>

<ul>
  <li><a href="documents/design/frames.html#Background">Background</a></li>
  <li><a href="documents/design/frames.html#Overview">Overview</a></li>
  <li><a href="documents/design/frames.html#Requirements">Requirements</a></li>
  <li><a href="documents/design/frames.html#Implementation">Implementation</a></li>
  <li><a href="documents/design/frames.html#Issues">Open Issues</a></li>
  <li><a href="documents/design/frames.html#Restrictions">Restrictions</a></li>
  <li><a href="documents/design/frames.html#FileFormat">File Format</a></li>
</ul>

<a name="Background"/>
<h3>Background</h3>
<p>
  Frames are used by <a href="documents/design/compounds.html">compounds</a>
  during the recomposition phase. This document discusses the implementation
  details of this part of the compound spec.
</p>

<a name="Overview"/>
<h3>Overview</h3>
<p>
  <img src="documents/design/frames.png" 
       alt="UML diagram of compound frames"/>
</p><p>
  Frames can be input frames or output frames. Output frames produce the data
  consumed by input frames. The common link between the output and input
  frames is the frame buffer. A frame buffer holds the data, which is
  organized into a set of images for each (OpenGL) framebuffer attachment -
  color, depth and stencil. Each image represents a 2D array of
  pixels. The default implementation uses at most one image per type is
  used. The application can implement a custom readback producing multiple
  images per type, in order to further minimize the amount of pixel data.
</p><p>
  A frame has a format, which defines the components of the framebuffer to
  be read back (output frame) or assembled (input frames). It has a viewport,
  which defines the fractional portion of the channel has to be read back
  (output) or which fractional portion of the corresponding output frame (input
  frames) has to be assembled.
</p>
  

<a name="Requirements"/>
<h3>Requirements</h3>
<p>
 Frames are used in the following way:
 <ul>
  <li>Output images for one output frame are produced by a single node.</li>
  <li>Images are send from the 'output' node to multiple 'input' nodes</li>
  <li>The input frame format may be a subset of the output frame
    format. Consequently, the node producing the output images only sends images
    to nodes if the input frame format matches.</li>
  <li>Same optimisation for other attributes, i.e., viewport, eye(?)</li>
  <li>Frames and images are relatively static during rendering. The objects
    should be reused from (config) frame to frame to avoid costly network
    instanciation and reallocation.</li>
 </ul>
</p>
<p>
 The following features must be implementable:
 <ul>
  <li>It must be possible to select a ready frame from a list of input frames,
    to allow early assembly when using multiple input frames.</li>
  <li>Different readback mechanisms: readPixels, FBO, hardware
    framegrabbers</li>
  <li>Different assemble mechanisms</li>
  <li>On-GPU storage if input and output frame are on the same pipe, using
    textures or FBO's</li>
 </ul>
</p>

<a name="Implementation"/>
<h3>Implementation</h3>
<p>
  The implementation should execute as follows:
  <pre>
    [readback callback]
    foreach frame
        foreach type
            start readback of image[s]
    foreach image of frame
        sync readback of image
        send image to all 'input' nodes
          Note: multiple consumers on a node should receive only one update
    foreach frame
        send frame ready to all 'input' nodes

    [assemble callback]
    (background receiving in recv thread)
    foreach frame
        sync frame ready .OR. select ready frame from frame list
        start draw frame
    foreach frame
        sync draw frame (maybe omit or defer until frame is reused?)
  </pre>
</p><p>
  Use monitor to determine readyness of frame buffer.
</p><p>
  Q: scope of frames and images when using multiple pipes per node.
  A: SCOPE_THREAD for frames to reference correct frame buffer for each thread.
     SCOPE_NODE for frame buffer, with merged data of all input frames on node.
     Images are not distributed objects. They are managed directly by the
     framebuffer and the data is distributed using command packets.
</p><p>
  Q: latency
  A: New frame buffer for each config frame (and recycle once obsolete)
</p><p>
  Images have to be pushed by the output node for optimal performance. The
  subscriber model of versioned objects does not work for this purpose, since
  the frame input and output relations may change every frame, due to load
  balancing, DPlex phase or other per-frame compound changes. Furthermore, the
  number of images per frame can vary.
</p><p>
  On the server:
  <pre>
    Compound::update
        prepare output frames (1st tree traversal)
           release old frame buffers based on frame number
           recycle new frame buffer
           set frame buffer data (output frame data)
           commit frame buffer (new version)
           set frame data (frame buffer id and version, 
                           viewport, format, eye, ...)
           commit frame
        prepare input frames (2nd tree traversal)     
           set current data (viewport, format, eye, ...)
           set frame buffer id and version from output frame
           commit frame

    Compound::updateChannel (per-channel task generation)
        foreach output frame
            if applicable (filter: format, vp, eye, already send to node)
                send readback task
                    [ output frame id and version ]
                      -> holds frame buffer id and version -> holds frame number
        foreach not-filtered output frame
            foreach input frame of output frame
                if applicable (filter: format, vp, eye, already send to node)
                filter duplicate nodes
                    send transmit task
                        [ output frame id and version, attrs ]
        foreach input frame
            if applicable (filter: format, vp, eye, already send to node)
                add to assemble task frames
                    [ input frame id and version ]
                      -> holds frame buffer id and version -> holds frame number
        if assemble task frame list not empty
            send assemble task containing frame list
  </pre>

  On the "output" node:
  <pre>
    readback task:
        start readback

    transmit task:
        send by the output frame's FrameBuffer:
            foreach matching image
                sync readback
                transmit image packet [ frame buffer version, type, vp, data ]
            transmit frame buffer ready [ frame number ]
  </pre>
    
  On the "input" node:
  <pre>
    assemble task
        foreach input frame
            sync to frame version
        call assemble()
            sync frame[s]
                wait for frame buffer images to reach version
            assemble frame[s]
    [recv thread]
        receive input image
            if version of images older than received image
                release images
                set version of images to received version
            save image into recycled Image object
        receive ready
            set image ready version
  </pre>
</p>

<h4>API</h4>
<p>
  Incomplete pseudocode of the API, look at the implementation for full
  details. A object of a given type has a different implementation on the
  server-side and client-side which share the same distributed data.
  <pre>
    class Frame
    {
        uint32_t frameBufferID;
        uint32_t frameBufferVersion;
    }
    class FrameBuffer
    {
        void addImage( Image::Type type, Image* image );
        // corresponding getters

        uint32_t        _versionImages;
        eqBase::Monitor _versionReady;
    };

    class Image
    {
        enum Type
        {
            TYPE_COLOR   = GL_COLOR_BUFFER_BIT
            TYPE_DEPTH   = GL_DEPTH_BUFFER_BIT,
            TYPE_STENCIL = GL_STENCIL_BUFFER_BIT
        };
        void startReadback( format, type, x, y, w, h );
        void syncReadback();
    };
  </pre>
</p>

<a name="Issues"/>
<h3>Open Issues</h3>
<p>
  Send optimisation for partial input frames, select ready frames from list for
  early assembly,
</p>

<a name="Restrictions"/>
<h3>Restrictions</h3>
<p>
  Only full images are sent to the nodes. If the input frame specifies a
  non-full viewport (which is relative to the output frame), the amount of data
  send will not be optimized at the moment. The same applies to the other
  attributes (format, eye, etc.).
</p>

<a name="FileFormat"/>
<h3>File Format</h3>
 <p>
   See <a href="documents/design/compounds.html#FileFormat">compound spec</a>.
 </p>
       
#include "footer.shtml"
